{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KnextKoder/Mein_LLM/blob/main/yor_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeHL-mlQt8IL"
      },
      "source": [
        "# 1. Introduction & Goal üéØ\n",
        "\n",
        "## Fine-tuning a Language Model for Translation\n",
        "\n",
        "Welcome! This notebook is your hands-on guide to fine-tuning a pre-trained model for a new task.\n",
        "We'll take a model that understands English and teach it how to translate from **English to Yoruba**.\n",
        "\n",
        "### What You'll Learn:\n",
        "1.  **Setup**: How to install and import the necessary libraries.\n",
        "2.  **Load Data**: How to load a standard translation dataset from the Hugging Face Hub.\n",
        "3.  **Preprocess**: How to prepare the text data for the model using a tokenizer.\n",
        "4.  **Fine-Tune**: The core process of training the model on the new data.\n",
        "5.  **Inference**: How to use your newly fine-tuned model to translate sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxnUerGqt8IO"
      },
      "outputs": [],
      "source": [
        "# 2. Setup üõ†Ô∏è | Installing Libraries\n",
        "# First things first, we need to install the libraries that will do the heavy lifting.\n",
        "\n",
        "# - **transformers**: Provides the pre-trained models (like T5) and the training tools.\n",
        "# - **datasets**: Makes it super easy to load datasets from the Hugging Face Hub.\n",
        "# - **sacrebleu**: A standard library for evaluating translation quality.\n",
        "# - **accelerate**: Helps PyTorch (the backend for transformers) run smoothly on GPUs or TPUs.\n",
        "\n",
        "!pip install transformers[torch] datasets sacrebleu accelerate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv8vhCZtt8IQ",
        "outputId": "f4c128f9-2189-4e2d-9ccb-31c03011534f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sample from our dataset:\n",
            "{'en': '\"Based on the advice of the Federal Ministry of Health and the NCDC, I am directing the cessation of all movements in Lagos and the FCT for an initial period of 14 days with effect from 11pm on Monday, 30th March 2020.', 'yo': 'N√≠pa √¨m·ªçÃÄr√†n l√°ti ·ªçÃÄd·ªçÃÄ √†w·ªçn √†j·ªç t√≥ ≈Ñ m√≥j√∫t√≥ √®t√≤ √¨lera √†ti √†j·ªç t√≥ ≈Ñ m√≥j√∫t√≥ gb√≠gb√≥gun ti √†√†r√πn l√≥r√≠l·∫πÃÅ √®d√® N√†√¨j√≠r√≠√†, n√≠tor√≠ n√°√† mo p√†·π£·∫π, p√© k√≥ n√≠ s√≠ w√≠w·ªçl√© t√†b√≠ j√≠j√°de n√≠l√π√∫ √àk√≥, √íg√πn √†ti FCT √Äb√∫j√° f√∫n odidi ·ªçj·ªçÃÅ m·∫πÃÅr√¨nl√° gb√°ko b·∫πÃÄr·∫πÃÄ l√°ti aago m·ªçÃÅk√†nl√°, ·ªçgb·ªçÃÄ·ªçj·ªçÃÅ, o·π£√π k·∫πta,·ªçd√∫n 2020.'}\n"
          ]
        }
      ],
      "source": [
        "# 3. Loading the Dataset üìö\n",
        "# We need data to teach our model. We'll use the 'opus_books' dataset, which contains pairs of sentences in English and French from translated books.\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load a small part of the dataset to keep training fast for this tutorial.\n",
        "# We'll use the first 1% of the pairs for this example.\n",
        "# raw_datasets = load_dataset(\"opus_books\", \"en-fr\", split=\"train[:1%]\")\n",
        "raw_datasets = load_dataset(\"0xmarvel/soro-en-yor\", split=\"train\")\n",
        "\n",
        "# The dataset is currently one big block. Let's split it into a training set and a testing set.\n",
        "# 90% for training, 10% for testing.\n",
        "split_datasets = raw_datasets.train_test_split(train_size=0.9, seed=42)\n",
        "\n",
        "# Rename the 'test' split to 'validation' which is a more common term in training.\n",
        "split_datasets[\"validation\"] = split_datasets.pop(\"test\")\n",
        "\n",
        "# Let's see what a sample looks like!\n",
        "print(\"A sample from our dataset:\")\n",
        "print(split_datasets[\"train\"][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "a2f49997b2ce4e208aee2ae63a50f1a2",
            "a22763d6c5194d4fbd70edb908aa1e63",
            "7a8c72660550492ba798af136ff54960",
            "ee83cac61a554a81810745cebcbf23f6",
            "417ac3d9574d468a992c82c25a7f2fa0",
            "b26d64b5d0ec4c00be0122f235037cb1",
            "c03ceab5e5bf43818fdd3c779ca2daa0",
            "e453702a3e0b487aaf7995e19075ac45",
            "73da1c415e6c4ced82fafb9aabcb55cc",
            "0792213d2ac94a1b89671f51f9ae8d48",
            "41a6204e9a9441bd986ec26dc1f90a20"
          ]
        },
        "id": "dqrA3_b7t8IR",
        "outputId": "3ef5fdbc-16b1-4bdd-a295-9eb0b43edbf1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/664 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2f49997b2ce4e208aee2ae63a50f1a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample of tokenized data (the model sees numbers, not words):\n",
            "{'en': '\"Based on the advice of the Federal Ministry of Health and the NCDC, I am directing the cessation of all movements in Lagos and the FCT for an initial period of 14 days with effect from 11pm on Monday, 30th March 2020.', 'yo': 'N√≠pa √¨m·ªçÃÄr√†n l√°ti ·ªçÃÄd·ªçÃÄ √†w·ªçn √†j·ªç t√≥ ≈Ñ m√≥j√∫t√≥ √®t√≤ √¨lera √†ti √†j·ªç t√≥ ≈Ñ m√≥j√∫t√≥ gb√≠gb√≥gun ti √†√†r√πn l√≥r√≠l·∫πÃÅ √®d√® N√†√¨j√≠r√≠√†, n√≠tor√≠ n√°√† mo p√†·π£·∫π, p√© k√≥ n√≠ s√≠ w√≠w·ªçl√© t√†b√≠ j√≠j√°de n√≠l√π√∫ √àk√≥, √íg√πn √†ti FCT √Äb√∫j√° f√∫n odidi ·ªçj·ªçÃÅ m·∫πÃÅr√¨nl√° gb√°ko b·∫πÃÄr·∫πÃÄ l√°ti aago m·ªçÃÅk√†nl√°, ·ªçgb·ªçÃÄ·ªçj·ªçÃÅ, o·π£√π k·∫πta,·ªçd√∫n 2020.', 'input_ids': [13959, 1566, 12, 6545, 14446, 9, 10, 96, 25557, 30, 8, 1867, 13, 8, 5034, 7849, 13, 1685, 11, 8, 445, 23125, 6, 27, 183, 3, 26243, 8, 1830, 7, 257, 13, 66, 9780, 16, 29461, 11, 8, 377, 6227, 21, 46, 2332, 1059, 13, 968, 477, 28, 1504, 45, 850, 2028, 30, 2089, 6, 604, 189, 1332, 6503, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [445, 2, 102, 9, 3, 2, 51, 2, 52, 85, 29, 3, 40, 2975, 17, 23, 3, 2, 26, 2, 3, 85, 210, 2, 29, 3, 85, 354, 2, 3, 17, 4922, 3, 2, 3, 51, 4922, 354, 2, 17, 4922, 3, 5115, 17, 2, 3, 2, 1171, 9, 3, 85, 17, 23, 3, 85, 354, 2, 3, 17, 4922, 3, 2, 3, 51, 4922, 354, 2, 17, 4922, 3, 122, 115, 2, 122, 115, 4922, 8765, 3, 17, 23, 3, 85, 85, 52, 23063, 29, 3, 40, 4922, 52, 2, 40, 2, 3, 5115, 26, 5115, 445, 85, 2, 354, 2, 52, 2, 85, 6, 3, 29, 2, 17, 127, 2, 3, 29, 2975, 85, 2288, 3, 102, 85, 2, 6, 3, 3890, 3, 157, 4922, 1]}\n"
          ]
        }
      ],
      "source": [
        "# 4. Preprocessing the Data ‚úçÔ∏è\n",
        "# Models don't understand words; they understand numbers. The process of converting words to numbers is called \"tokenization\".\n",
        "# We'll use a \"tokenizer\" that was created alongside our pre-trained model to ensure the numbers match what the model expects.\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# The model we'll be fine-tuning is 't5-small'. It's a good balance of size and performance for a tutorial.\n",
        "model_checkpoint = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "source_lang = \"en\"\n",
        "target_lang = \"yo\"\n",
        "\n",
        "# T5 is a sequence-to-sequence model. It needs a specific prefix to know what task it should be doing.\n",
        "# For translation, we'll tell it \"translate English to French: \".\n",
        "prefix = \"translate English to Yoruba: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    \"\"\"This function takes a batch of examples and tokenizes them.\"\"\"\n",
        "    # Access the lists of sentences directly using the language keys\n",
        "    inputs = [prefix + text for text in examples[source_lang]]\n",
        "    targets = [text for text in examples[target_lang]]\n",
        "\n",
        "    # Tokenize the inputs and targets\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
        "    labels = tokenizer(text_target=targets, max_length=128, truncation=True)\n",
        "\n",
        "    # The 'labels' are what the model should learn to predict.\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Now, apply this function to our entire dataset. The 'map' function is a powerful way to do this quickly.\n",
        "tokenized_datasets = split_datasets.map(preprocess_function, batched=True)\n",
        "\n",
        "print(\"\\nSample of tokenized data (the model sees numbers, not words):\")\n",
        "print(tokenized_datasets[\"train\"][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uV7uuj90t8IS",
        "outputId": "2932e0a3-2ae4-4280-ee78-56b170d9489d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4061303142.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the fine-tuning process...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='31014' max='37400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [31014/37400 2:14:16 < 27:39, 3.85 it/s, Epoch 82.92/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.473315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.857800</td>\n",
              "      <td>2.270584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.435500</td>\n",
              "      <td>2.158744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.435500</td>\n",
              "      <td>2.085432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.298900</td>\n",
              "      <td>2.030452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.209300</td>\n",
              "      <td>1.984345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.136500</td>\n",
              "      <td>1.947982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.136500</td>\n",
              "      <td>1.915529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.091900</td>\n",
              "      <td>1.887195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.047500</td>\n",
              "      <td>1.862744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.014300</td>\n",
              "      <td>1.839310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.014300</td>\n",
              "      <td>1.817323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.975500</td>\n",
              "      <td>1.798197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.950300</td>\n",
              "      <td>1.779314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.927300</td>\n",
              "      <td>1.763311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.927300</td>\n",
              "      <td>1.744528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.901200</td>\n",
              "      <td>1.730352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.882200</td>\n",
              "      <td>1.715056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.850400</td>\n",
              "      <td>1.702266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.850400</td>\n",
              "      <td>1.689173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.841100</td>\n",
              "      <td>1.677670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.822000</td>\n",
              "      <td>1.667122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.802100</td>\n",
              "      <td>1.656209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.802100</td>\n",
              "      <td>1.644815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.791000</td>\n",
              "      <td>1.636802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.774400</td>\n",
              "      <td>1.626453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.760100</td>\n",
              "      <td>1.617263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.760100</td>\n",
              "      <td>1.609516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.748100</td>\n",
              "      <td>1.599764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.733200</td>\n",
              "      <td>1.591473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.722400</td>\n",
              "      <td>1.584616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.722400</td>\n",
              "      <td>1.577516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.710500</td>\n",
              "      <td>1.570230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.700400</td>\n",
              "      <td>1.563242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.685300</td>\n",
              "      <td>1.556256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.685300</td>\n",
              "      <td>1.550669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.678900</td>\n",
              "      <td>1.544403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.669100</td>\n",
              "      <td>1.537948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.665000</td>\n",
              "      <td>1.532212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.665000</td>\n",
              "      <td>1.527085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.647600</td>\n",
              "      <td>1.520899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.644200</td>\n",
              "      <td>1.516190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.634600</td>\n",
              "      <td>1.511008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.634600</td>\n",
              "      <td>1.506839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.626800</td>\n",
              "      <td>1.501558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.615200</td>\n",
              "      <td>1.497023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.612000</td>\n",
              "      <td>1.493612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.612000</td>\n",
              "      <td>1.488236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.608000</td>\n",
              "      <td>1.485001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.595500</td>\n",
              "      <td>1.482244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.592900</td>\n",
              "      <td>1.477973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.592900</td>\n",
              "      <td>1.472730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.583700</td>\n",
              "      <td>1.470640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.578500</td>\n",
              "      <td>1.466081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.574100</td>\n",
              "      <td>1.463638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.574100</td>\n",
              "      <td>1.460243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.565800</td>\n",
              "      <td>1.456783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.562700</td>\n",
              "      <td>1.454129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.557300</td>\n",
              "      <td>1.452623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.557300</td>\n",
              "      <td>1.448848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.555900</td>\n",
              "      <td>1.446213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.544500</td>\n",
              "      <td>1.442838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1.545500</td>\n",
              "      <td>1.440295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.545500</td>\n",
              "      <td>1.438599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.542200</td>\n",
              "      <td>1.435496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.534800</td>\n",
              "      <td>1.433748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.528000</td>\n",
              "      <td>1.430286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.528000</td>\n",
              "      <td>1.428906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.530300</td>\n",
              "      <td>1.427023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.523600</td>\n",
              "      <td>1.424703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1.521200</td>\n",
              "      <td>1.422797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.521200</td>\n",
              "      <td>1.421820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.517000</td>\n",
              "      <td>1.420125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.515000</td>\n",
              "      <td>1.417979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.511100</td>\n",
              "      <td>1.417277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.511100</td>\n",
              "      <td>1.415419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.509400</td>\n",
              "      <td>1.413342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.506100</td>\n",
              "      <td>1.412183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.505200</td>\n",
              "      <td>1.411567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.505200</td>\n",
              "      <td>1.410232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.500800</td>\n",
              "      <td>1.409462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.498300</td>\n",
              "      <td>1.407861</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='37400' max='37400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [37400/37400 2:42:10, Epoch 100/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.473315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.857800</td>\n",
              "      <td>2.270584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.435500</td>\n",
              "      <td>2.158744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.435500</td>\n",
              "      <td>2.085432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.298900</td>\n",
              "      <td>2.030452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.209300</td>\n",
              "      <td>1.984345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.136500</td>\n",
              "      <td>1.947982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.136500</td>\n",
              "      <td>1.915529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.091900</td>\n",
              "      <td>1.887195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.047500</td>\n",
              "      <td>1.862744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.014300</td>\n",
              "      <td>1.839310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2.014300</td>\n",
              "      <td>1.817323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.975500</td>\n",
              "      <td>1.798197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.950300</td>\n",
              "      <td>1.779314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.927300</td>\n",
              "      <td>1.763311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.927300</td>\n",
              "      <td>1.744528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.901200</td>\n",
              "      <td>1.730352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.882200</td>\n",
              "      <td>1.715056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.850400</td>\n",
              "      <td>1.702266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.850400</td>\n",
              "      <td>1.689173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.841100</td>\n",
              "      <td>1.677670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.822000</td>\n",
              "      <td>1.667122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.802100</td>\n",
              "      <td>1.656209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.802100</td>\n",
              "      <td>1.644815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.791000</td>\n",
              "      <td>1.636802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.774400</td>\n",
              "      <td>1.626453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.760100</td>\n",
              "      <td>1.617263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.760100</td>\n",
              "      <td>1.609516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.748100</td>\n",
              "      <td>1.599764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.733200</td>\n",
              "      <td>1.591473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.722400</td>\n",
              "      <td>1.584616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.722400</td>\n",
              "      <td>1.577516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.710500</td>\n",
              "      <td>1.570230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.700400</td>\n",
              "      <td>1.563242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.685300</td>\n",
              "      <td>1.556256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.685300</td>\n",
              "      <td>1.550669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.678900</td>\n",
              "      <td>1.544403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.669100</td>\n",
              "      <td>1.537948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.665000</td>\n",
              "      <td>1.532212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.665000</td>\n",
              "      <td>1.527085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.647600</td>\n",
              "      <td>1.520899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.644200</td>\n",
              "      <td>1.516190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.634600</td>\n",
              "      <td>1.511008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.634600</td>\n",
              "      <td>1.506839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.626800</td>\n",
              "      <td>1.501558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.615200</td>\n",
              "      <td>1.497023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.612000</td>\n",
              "      <td>1.493612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.612000</td>\n",
              "      <td>1.488236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.608000</td>\n",
              "      <td>1.485001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.595500</td>\n",
              "      <td>1.482244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.592900</td>\n",
              "      <td>1.477973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.592900</td>\n",
              "      <td>1.472730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.583700</td>\n",
              "      <td>1.470640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.578500</td>\n",
              "      <td>1.466081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.574100</td>\n",
              "      <td>1.463638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.574100</td>\n",
              "      <td>1.460243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.565800</td>\n",
              "      <td>1.456783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.562700</td>\n",
              "      <td>1.454129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.557300</td>\n",
              "      <td>1.452623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.557300</td>\n",
              "      <td>1.448848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.555900</td>\n",
              "      <td>1.446213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.544500</td>\n",
              "      <td>1.442838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1.545500</td>\n",
              "      <td>1.440295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.545500</td>\n",
              "      <td>1.438599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.542200</td>\n",
              "      <td>1.435496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.534800</td>\n",
              "      <td>1.433748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.528000</td>\n",
              "      <td>1.430286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.528000</td>\n",
              "      <td>1.428906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.530300</td>\n",
              "      <td>1.427023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.523600</td>\n",
              "      <td>1.424703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1.521200</td>\n",
              "      <td>1.422797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.521200</td>\n",
              "      <td>1.421820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.517000</td>\n",
              "      <td>1.420125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.515000</td>\n",
              "      <td>1.417979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.511100</td>\n",
              "      <td>1.417277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.511100</td>\n",
              "      <td>1.415419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.509400</td>\n",
              "      <td>1.413342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.506100</td>\n",
              "      <td>1.412183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.505200</td>\n",
              "      <td>1.411567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.505200</td>\n",
              "      <td>1.410232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.500800</td>\n",
              "      <td>1.409462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.498300</td>\n",
              "      <td>1.407861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>1.502100</td>\n",
              "      <td>1.407136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.502100</td>\n",
              "      <td>1.406049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.491400</td>\n",
              "      <td>1.404914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.495200</td>\n",
              "      <td>1.403863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.494300</td>\n",
              "      <td>1.403230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.494300</td>\n",
              "      <td>1.402284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>1.491800</td>\n",
              "      <td>1.401674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.491500</td>\n",
              "      <td>1.401150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>1.488700</td>\n",
              "      <td>1.400563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>1.488700</td>\n",
              "      <td>1.400165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>1.486600</td>\n",
              "      <td>1.399376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1.488100</td>\n",
              "      <td>1.399125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.485200</td>\n",
              "      <td>1.398891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1.485200</td>\n",
              "      <td>1.398435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>1.487400</td>\n",
              "      <td>1.398285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>1.488400</td>\n",
              "      <td>1.398239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>1.483200</td>\n",
              "      <td>1.398044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.483200</td>\n",
              "      <td>1.397994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# 5. Fine-Tuning the Model üî•\n",
        "# This is where the magic happens! We'll load the pre-trained T5 model and set up a \"Trainer\" that handles the entire training loop for us.\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "\n",
        "# Load the pre-trained T5 model.\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "\n",
        "# A data collator is a helper that batches our tokenized data together nicely for the model.\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "# Define the training arguments. These are like settings for our training session.\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"t5-small-en-to-yor\",          # Where to save the model\n",
        "    eval_strategy=\"epoch\",            # Evaluate at the end of each epoch\n",
        "    learning_rate=2e-5,                     # A standard learning rate for fine-tuning\n",
        "    per_device_train_batch_size=16,         # How many examples to process at once during training\n",
        "    per_device_eval_batch_size=16,          # How many examples to process at once during evaluation\n",
        "    weight_decay=0.01,                      # Helps prevent overfitting\n",
        "    save_total_limit=3,                     # Only keep the best 3 model checkpoints\n",
        "    num_train_epochs=100,                     # We'll train for 3 full passes over the data\n",
        "    predict_with_generate=True,             # Necessary for sequence-to-sequence tasks\n",
        "    push_to_hub=False,                      # Set to True if you want to upload to Hugging Face Hub\n",
        ")\n",
        "\n",
        "# Create the Trainer object.\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Start training! This will take a few minutes on a Colab GPU.\n",
        "# Make sure your runtime is set to GPU (Runtime -> Change runtime type -> T4 GPU)\n",
        "print(\"Starting the fine-tuning process...\")\n",
        "trainer.train()\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhsPqzSjt8IT",
        "outputId": "aedbdedd-2eef-4b2a-ee45-fa0a470c2677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: t5-small-en-to-yor/checkpoint-37400\n",
            "English: Dogs.\n",
            "Model's Yoruba Translation: wn   e.\n",
            "\n",
            "--- Another example ---\n",
            "English: Bird.\n",
            "Model's Yoruba Translation: wn m.\n"
          ]
        }
      ],
      "source": [
        "# 6. Inference (Using Your Model) üó£Ô∏è\n",
        "# The model is trained! Now for the fun part: let's give it an English sentence and see how it does.\n",
        "\n",
        "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Find the latest checkpoint directory\n",
        "output_dir = \"t5-small-en-to-yor\"\n",
        "checkpoints = [os.path.join(output_dir, d) for d in os.listdir(output_dir) if d.startswith('checkpoint-')]\n",
        "latest_checkpoint = max(checkpoints, key=os.path.getmtime)\n",
        "\n",
        "print(f\"Loading model from: {latest_checkpoint}\")\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(latest_checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(latest_checkpoint)\n",
        "\n",
        "# Define the prefix for the translation task\n",
        "prefix = \"translate English to Yoruba: \"\n",
        "\n",
        "def translate_en_to_yor(text):\n",
        "    \"\"\"Translates English text to Yoruba using the fine-tuned model.\"\"\"\n",
        "    inputs = [prefix + text]\n",
        "    # Tokenize the input text\n",
        "    tokenized_inputs = tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Generate the translation\n",
        "    # Add a check to move tensors to GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "        tokenized_inputs = {k: v.to(\"cuda\") for k, v in tokenized_inputs.items()}\n",
        "        model.to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(**tokenized_inputs, max_length=128)\n",
        "\n",
        "    # Decode the generated tokens back to text\n",
        "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return translated_text\n",
        "\n",
        "# Let's try translating a sentence.\n",
        "english_sentence = \"Dogs.\"\n",
        "yoruba_translation = translate_en_to_yor(english_sentence)\n",
        "\n",
        "print(f\"English: {english_sentence}\")\n",
        "print(f\"Model's Yoruba Translation: {yoruba_translation}\")\n",
        "\n",
        "print(\"\\n--- Another example ---\")\n",
        "english_sentence_2 = \"Bird.\"\n",
        "yoruba_translation_2 = translate_en_to_yor(english_sentence_2)\n",
        "print(f\"English: {english_sentence_2}\")\n",
        "print(f\"Model's Yoruba Translation: {yoruba_translation_2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTxREhgMt8IT"
      },
      "source": [
        "# 7. Conclusion & Next Steps üéâ\n",
        "\n",
        "## Congratulations!\n",
        "\n",
        "You have successfully fine-tuned a pre-trained T5 model to translate from English to French.\n",
        "\n",
        "### What We Accomplished:\n",
        "- Loaded and prepared a real-world translation dataset.\n",
        "- Tokenized the text so the model could understand it.\n",
        "- Ran a complete fine-tuning process using the Hugging Face Trainer.\n",
        "- Used the final model to generate new translations.\n",
        "\n",
        "### Where to Go From Here:\n",
        "- **Train for longer**: Training for more epochs on more data will improve performance.\n",
        "- **Try a larger model**: Using `t5-base` or `t5-large` will yield much better results (but take longer to train).\n",
        "- **Translate other languages**: Find another dataset on the Hugging Face Hub and try fine-tuning for a different language pair!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2f49997b2ce4e208aee2ae63a50f1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a22763d6c5194d4fbd70edb908aa1e63",
              "IPY_MODEL_7a8c72660550492ba798af136ff54960",
              "IPY_MODEL_ee83cac61a554a81810745cebcbf23f6"
            ],
            "layout": "IPY_MODEL_417ac3d9574d468a992c82c25a7f2fa0"
          }
        },
        "a22763d6c5194d4fbd70edb908aa1e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b26d64b5d0ec4c00be0122f235037cb1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c03ceab5e5bf43818fdd3c779ca2daa0",
            "value": "Map:‚Äá100%"
          }
        },
        "7a8c72660550492ba798af136ff54960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e453702a3e0b487aaf7995e19075ac45",
            "max": 664,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73da1c415e6c4ced82fafb9aabcb55cc",
            "value": 664
          }
        },
        "ee83cac61a554a81810745cebcbf23f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0792213d2ac94a1b89671f51f9ae8d48",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_41a6204e9a9441bd986ec26dc1f90a20",
            "value": "‚Äá664/664‚Äá[00:00&lt;00:00,‚Äá1933.01‚Äáexamples/s]"
          }
        },
        "417ac3d9574d468a992c82c25a7f2fa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b26d64b5d0ec4c00be0122f235037cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c03ceab5e5bf43818fdd3c779ca2daa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e453702a3e0b487aaf7995e19075ac45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73da1c415e6c4ced82fafb9aabcb55cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0792213d2ac94a1b89671f51f9ae8d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a6204e9a9441bd986ec26dc1f90a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}